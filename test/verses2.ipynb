{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/toure215/BERT_phonetic/test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ah why this boding start this sudden pain</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>that wings my pulse and shoots from vein to vein</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>what mean regardless of yon midnight bell</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>these earthborn visions saddening o'er my cell</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>what strange disorder prompts these thoughts t...</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>these sighs to murmur and these tears to flow</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>'tis she 'tis eloisa's form restor'd</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>once a pure saint and more than saints ador'd</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>she comes in all her killing charms confest</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>glares thro' the gloom and pours upon my breast</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              Verse   Meter  char_count\n",
       "0   0          ah why this boding start this sudden pain  iambic           6\n",
       "1   1   that wings my pulse and shoots from vein to vein  iambic           6\n",
       "2   2          what mean regardless of yon midnight bell  iambic           6\n",
       "3   3     these earthborn visions saddening o'er my cell  iambic           6\n",
       "4   4  what strange disorder prompts these thoughts t...  iambic           6\n",
       "5   5      these sighs to murmur and these tears to flow  iambic           6\n",
       "6   6               'tis she 'tis eloisa's form restor'd  iambic           6\n",
       "7   7      once a pure saint and more than saints ador'd  iambic           6\n",
       "8   8        she comes in all her killing charms confest  iambic           6\n",
       "9   9    glares thro' the gloom and pours upon my breast  iambic           6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "pd_data_frame = pd.read_csv(\"/home/toure215/BERT_phonetic/DATASETS/verses/verses.csv\")\n",
    "pd_data_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['iambic' 'anapaestic' 'trochaic' 'dactyl']\n",
      "[ 6 10  8]\n"
     ]
    }
   ],
   "source": [
    "print(pd_data_frame[\"Meter\"].nunique())\n",
    "print(pd_data_frame.Meter.unique())\n",
    "print(pd_data_frame.char_count.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iambic': 0, 'anapaestic': 1, 'trochaic': 2, 'dactyl': 3}\n",
      "{0: 'iambic', 1: 'anapaestic', 2: 'trochaic', 3: 'dactyl'}\n"
     ]
    }
   ],
   "source": [
    "label_to_idx = {label: i for i, label in enumerate(pd_data_frame.Meter.unique())}\n",
    "idx_to_label = {i: label for i, label in enumerate(pd_data_frame.Meter.unique())}\n",
    "print(label_to_idx)\n",
    "print(idx_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_frame[\"label\"] = pd_data_frame[\"Meter\"].map(lambda x: label_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "      <th>char_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ah why this boding start this sudden pain</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>that wings my pulse and shoots from vein to vein</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>what mean regardless of yon midnight bell</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>these earthborn visions saddening o'er my cell</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>what strange disorder prompts these thoughts t...</td>\n",
       "      <td>iambic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              Verse   Meter  char_count  \\\n",
       "0   0          ah why this boding start this sudden pain  iambic           6   \n",
       "1   1   that wings my pulse and shoots from vein to vein  iambic           6   \n",
       "2   2          what mean regardless of yon midnight bell  iambic           6   \n",
       "3   3     these earthborn visions saddening o'er my cell  iambic           6   \n",
       "4   4  what strange disorder prompts these thoughts t...  iambic           6   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd_data_frame[\"label\"].nunique())\n",
    "pd_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_frame = pd_data_frame.drop(columns=\"char_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_frame.head()\n",
    "pd_train, pd_test = train_test_split(pd_data_frame, test_size=0.2, random_state=42)\n",
    "pd_train, pd_val = train_test_split(pd_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n0 : 119497\n",
      "n1 : 3488\n",
      "n2 : 3489\n",
      "n3 : 886\n"
     ]
    }
   ],
   "source": [
    "n0 = pd_train[\"label\"][pd_train[\"label\"] == 0].count()\n",
    "n1 = pd_train[\"label\"][pd_train[\"label\"] == 1].count()\n",
    "n2 = pd_train[\"label\"][pd_train[\"label\"] == 2].count()\n",
    "n3 = pd_train[\"label\"][pd_train[\"label\"] == 3].count()\n",
    "print(\"n0 :\", n0)\n",
    "print(\"n1 :\", n1)\n",
    "print(\"n2 :\", n2)\n",
    "print(\"n3 :\", n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55872</td>\n",
       "      <td>the windy summit wild and high</td>\n",
       "      <td>trochaic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200358</td>\n",
       "      <td>then came the shepherd back with his bleating ...</td>\n",
       "      <td>dactyl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181192</td>\n",
       "      <td>pale as i lay beneath thy ebon wand</td>\n",
       "      <td>iambic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201875</td>\n",
       "      <td>hedividedwithhispeople</td>\n",
       "      <td>trochaic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3126</td>\n",
       "      <td>pastora by chance hasten'd by</td>\n",
       "      <td>anapaestic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              Verse       Meter  \\\n",
       "0   55872                     the windy summit wild and high    trochaic   \n",
       "1  200358  then came the shepherd back with his bleating ...      dactyl   \n",
       "2  181192                pale as i lay beneath thy ebon wand      iambic   \n",
       "3  201875                             hedividedwithhispeople    trochaic   \n",
       "4    3126                      pastora by chance hasten'd by  anapaestic   \n",
       "\n",
       "   label  \n",
       "0      2  \n",
       "1      3  \n",
       "2      0  \n",
       "3      2  \n",
       "4      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = pd_train[pd_train[\"label\"] == 0]\n",
    "d1 = pd_train[pd_train[\"label\"] == 1]\n",
    "d2 = pd_train[pd_train[\"label\"] == 2]\n",
    "d3 = pd_train[pd_train[\"label\"] == 3]\n",
    "\n",
    "d1_duplicated = pd.concat([d1] * (n0 // n1), ignore_index=True)\n",
    "d2_duplicated = pd.concat([d2] * (n0 // n2), ignore_index=True)\n",
    "d3_duplicated = pd.concat([d3] * (n0 // n3), ignore_index=True)\n",
    "\n",
    "pd_train = pd.concat(\n",
    "    [d0, d1_duplicated, d2_duplicated, d3_duplicated], ignore_index=True\n",
    ")\n",
    "pd_train = pd_train.sample(frac=1).reset_index(drop=True)\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475439\n",
      "           id   Verse   Meter\n",
      "label                        \n",
      "0      119497  119497  119497\n",
      "1      118592  118592  118592\n",
      "2      118626  118626  118626\n",
      "3      118724  118724  118724\n"
     ]
    }
   ],
   "source": [
    "print(len(pd_train))\n",
    "print(pd_train.groupby(\"label\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd_train.sample(frac=1).reset_index(drop=True)\n",
    "pd_val = pd_val.sample(frac=1).reset_index(drop=True)\n",
    "pd_test = pd_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_pandas(pd_train)\n",
    "val = Dataset.from_pandas(pd_val)\n",
    "test = Dataset.from_pandas(pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label'],\n",
       "        num_rows: 475439\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label'],\n",
       "        num_rows: 39801\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label'],\n",
       "        num_rows: 31841\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verses_dataset = DatasetDict({\"train\": train, \"test\": test, \"validation\": val})\n",
    "verses_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea209b62dc84973a7c27aaf8a1e03fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/475439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffddd4a34ce4f2298fb74ff366fe31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/39801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e70a3f9a18444aa5eb647c951f2b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/31841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verses_dataset.save_to_disk(\n",
    "    \"/home/toure215/BERT_phonetic/DATASETS/verses/verses_dup_hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=4,\n",
    "    id2label=idx_to_label,\n",
    "    label2id=label_to_idx,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0fd382fcd9439e93918a11d2ad86ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/475439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b312f839664442aae2a4d0480d687c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/39801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305af28ff68a4994bf5dc7a01ea66ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/31841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Meter', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 475439\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Meter', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 39801\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'Meter', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 31841\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Verse\"], padding=False, truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "dataset_hf_tokenized = verses_dataset.map(\n",
    "    tokenize_function, remove_columns=[\"Verse\"], num_proc=15\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(dataset_hf_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "import torch\n",
    "\n",
    "# labels = dataset_hf_tokenized[\"train\"][\"label\"]\n",
    "# class_count = torch.bincount(torch.tensor(labels))\n",
    "# class_weights = 1.0 / class_count.float()\n",
    "# sample_weight = torch.tensor([class_weights[t] for t in labels])\n",
    "# sampler = WeightedRandomSampler(weights=sample_weight, num_samples=len(sample_weight), replacement=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset_hf_tokenized[\"train\"], batch_size=8, sampler=sampler, collate_fn=data_collator)\n",
    "\n",
    "# for i, batch in enumerate(train_loader):\n",
    "#     print(batch[\"labels\"])\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.y_train = self.train_dataset[\"label\"]\n",
    "        class_count = torch.bincount(torch.tensor(self.y_train))\n",
    "        class_weights = 1.0 / class_count.float()\n",
    "        self.sample_weight = torch.tensor([class_weights[t] for t in self.y_train])\n",
    "        self.sampler = WeightedRandomSampler(\n",
    "            weights=self.sample_weight,\n",
    "            num_samples=len(self.sample_weight),\n",
    "            replacement=True,\n",
    "        )\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        def collate_and_move_to_device(batch):\n",
    "            batch = self.data_collator(batch)\n",
    "            return {\n",
    "                k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in batch.items()\n",
    "            }\n",
    "\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            sampler=self.sampler,\n",
    "            collate_fn=collate_and_move_to_device,\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        weight = torch.tensor(\n",
    "            compute_class_weight(\n",
    "                class_weight=\"balanced\",\n",
    "                classes=np.unique(self.y_train),\n",
    "                y=self.y_train,\n",
    "            ),\n",
    "            device=\"cuda\",\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/ety_bert\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_hf_tokenized[\"train\"],\n",
    "    eval_dataset=dataset_hf_tokenized[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf1567c76a14d578dc23de5becf395d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7258bf8972412c8e74cabb683962c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3059937059879303, 'eval_runtime': 3.0041, 'eval_samples_per_second': 10599.034, 'eval_steps_per_second': 41.609, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe466f67b3d401b957f2818ac7b010c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36933380365371704, 'eval_runtime': 2.8626, 'eval_samples_per_second': 11123.168, 'eval_steps_per_second': 43.667, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd37db6933544f5fa8659f46e56e7706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40441596508026123, 'eval_runtime': 2.9692, 'eval_samples_per_second': 10723.63, 'eval_steps_per_second': 42.098, 'epoch': 3.0}\n",
      "{'train_runtime': 388.6662, 'train_samples_per_second': 3669.774, 'train_steps_per_second': 14.341, 'train_loss': 0.05718245709887704, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5574, training_loss=0.05718245709887704, metrics={'train_runtime': 388.6662, 'train_samples_per_second': 3669.774, 'train_steps_per_second': 14.341, 'total_flos': 1.4802463655568264e+16, 'train_loss': 0.05718245709887704, 'epoch': 3.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d9ab62787a4555a5e75df4e06b1ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9490967563629055\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(dataset_hf_tokenized[\"test\"])\n",
    "preds, labels = predictions.predictions, predictions.label_ids\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "print(np.mean(preds == labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6524)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "accuracy = MulticlassAccuracy(num_classes=4, average=\"macro\")\n",
    "acc = accuracy(torch.tensor(preds), torch.tensor(labels))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a39e2afad1441beb9b8552f43b5a189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/589 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc53b5a9d20f44afbac49d5001c1b60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b489f19473dd44a8aaf1e014c4a51431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1669702b8d4eff8dbd5948c6b09d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6923468c546140fa8452024c83897178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phonetic_bert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1\", num_labels=4\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import epitran\n",
    "\n",
    "epi = epitran.Epitran(\"eng-Latn\")\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def cahed_xsampa(word):\n",
    "    return \"\".join(epi.xsampa_list(word))\n",
    "\n",
    "\n",
    "def translate_verse_to_phonetic(verse):\n",
    "    return \" \".join([cahed_xsampa(word) for word in verse.split()])\n",
    "\n",
    "\n",
    "def translate_to_phonetic(examples):\n",
    "    return {\n",
    "        \"Verse\": [translate_verse_to_phonetic(verse) for verse in examples[\"Verse\"]],\n",
    "        \"Original\": examples[\"Verse\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85faf05e5d2c44c6b605b10b359287b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/475439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a13850f27044f19b25fb2a414baca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/39801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce19d472762f420c854a1a64df3d359e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/31841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e98ea58ebb44cf4a5f7e97ad3037198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/475439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a3c0b5e46843d1b665adb4a6844dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/39801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8771d6b9b4694cd8879e442a82a621ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/31841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phonetic_dataset = verses_dataset.map(translate_to_phonetic, num_proc=15, batched=True)\n",
    "phonetic_dataset.save_to_disk(\n",
    "    \"/home/toure215/BERT_phonetic/DATASETS/verses/phonetic_verses_dup_hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1930b3402f4818943bbadb409b902e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/475439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485751b57d3a4555899df844688519b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/39801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5e0520cc4842e7b4b61e3e43cadd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/31841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phonetic_dataset_tokenized = phonetic_dataset.map(\n",
    "    tokenize_function,\n",
    "    remove_columns=[\"id\", \"Verse\", \"Meter\", \"Original\"],\n",
    "    num_proc=15,\n",
    "    batched=True,\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/ety_bert_phonetic\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=phonetic_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=phonetic_dataset_tokenized[\"train\"],\n",
    "    eval_dataset=phonetic_dataset_tokenized[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6341636d314061b308943d4f1b6c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e80bee32fa4b0f954df1bbbdef2fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2672980725765228, 'eval_runtime': 3.5802, 'eval_samples_per_second': 8893.713, 'eval_steps_per_second': 34.915, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851c73e9d745400abe3cd7cd67fdcebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30624884366989136, 'eval_runtime': 3.6791, 'eval_samples_per_second': 8654.478, 'eval_steps_per_second': 33.975, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672b58955af648d9bd4eff90a159a321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3388756215572357, 'eval_runtime': 3.4305, 'eval_samples_per_second': 9281.766, 'eval_steps_per_second': 36.438, 'epoch': 3.0}\n",
      "{'train_runtime': 520.2915, 'train_samples_per_second': 2741.381, 'train_steps_per_second': 10.713, 'train_loss': 0.05331154814064182, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5574, training_loss=0.05331154814064182, metrics={'train_runtime': 520.2915, 'train_samples_per_second': 2741.381, 'train_steps_per_second': 10.713, 'total_flos': 2.459148172263276e+16, 'train_loss': 0.05331154814064182, 'epoch': 3.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154b252f8ee84d018550ee1547875579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9554533805683274\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(phonetic_dataset_tokenized[\"test\"])\n",
    "preds, labels = predictions.predictions, predictions.label_ids\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "print(np.mean(preds == labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6824)\n"
     ]
    }
   ],
   "source": [
    "accuracy = MulticlassAccuracy(num_classes=4, average=\"macro\")\n",
    "acc = accuracy(torch.tensor(preds), torch.tensor(labels))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(pd_data_frame, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.1, random_state=42)\n",
    "\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "val = val.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_pandas(train)\n",
    "val = Dataset.from_pandas(val)\n",
    "test = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label'],\n",
       "        num_rows: 161190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label'],\n",
       "        num_rows: 19901\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label'],\n",
       "        num_rows: 17911\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse_hf = DatasetDict({\"train\": train, \"test\": test, \"validation\": val})\n",
    "verse_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e3591a00b8483bbf62b60c6f767383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/161190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b65450e8dd84b52bd4ada3acba3c624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/19901 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608352623d88412385c2835e4b2af647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/17911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verse_hf.save_to_disk(\"/home/toure215/BERT_phonetic/DATASETS/verses/verse_hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc679152fd84417683ab53adc0746b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/161190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8872b736dd8c490fa913d19e280c49a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/19901 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945d61fcaeca4a0b97299db63731bf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/17911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label', 'Original'],\n",
       "        num_rows: 161190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label', 'Original'],\n",
       "        num_rows: 19901\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'Verse', 'Meter', 'label', 'Original'],\n",
       "        num_rows: 17911\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonetic_verse_hf = verse_hf.map(translate_to_phonetic, num_proc=15, batched=True)\n",
    "phonetic_verse_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54a39a9791c4e13b46fab83f5648adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/161190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2577a1eff52c42bcac6b52c6a048cc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/19901 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f9ac7f361c46919a26ba2dd737304c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/17911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phonetic_verse_hf.save_to_disk(\n",
    "    \"/home/toure215/BERT_phonetic/DATASETS/verses/phonetic_verse_hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m bert_model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m phonetic_bert\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "del bert_model\n",
    "del phonetic_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
