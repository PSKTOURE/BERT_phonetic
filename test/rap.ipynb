{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import epitran\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "import kagglehub\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'validation']\n",
      "v{lkIr\\i@ kr\\An@k@lz ajIi 3\n",
      "\n",
      "sEndZ now v{lkIr\\i@   Vnr\\IkOr\\dId kr\\An@k@lz dZ{p@niz    lIt  v{lkIr\\i@ Vv D@ b{t@lfild   kAm@nli r\\@fr\\=d t@ {z v{lkIr\\i@ kr\\An@k@lz ajIi awtsajd dZ@p{n  Iz @ t{ktIk@l r\\owl plejIN vIdiow gejm dIvEl@pt baj sig@ {nd midi@  vIZ@n fOr\\ D@ plejstejS@n pOr\\t@b@l  r\\ilist In dZ{njuEr\\i  In dZ@p{n  It Iz D@ Tr\\=d gejm In D@ v{lkIr\\i@ sIr\\iz  EmplojIN D@ sejm fjuZ@n Vv t{ktIk@l {nd r\\il tajm gAmplej {z Its pr\\Ed@sEsr\\=z  D@ stOr\\i r\\Vnz pEr\\@lEl t@ D@ fr\\=st gejm {nd fAlowz D@  nejml@s   @ pin@l 78\n",
      "\n",
      "mIl@tEr\\i jun@t sr\\=vIN D@ nejS@n Vv g{li@ dUr\\IN D@ sEk@nd jUr\\owp{n wOr\\ hu pr\\=fOr\\m sikr\\@t bl{k Apr\\=ejS@nz {nd Ar\\ pIt@d @gEnst D@ ImpIr\\i@l jun@t  k@l@m@ti r\\ejv@n   26\n",
      "\n",
      "D@ gejm bIg{n dIvEl@pm@nt In   k{r\\iIN owvr\\= @ lAr\\dZ pOr\\S@n Vv D@ wr\\=k dVn An v{lkIr\\i@ kr\\An@k@lz Ii  wajl It r\\Itejnd D@ st{ndr\\=d fitSr\\=z Vv D@ sIr\\iz  It Olsow Vndr\\=wEnt mVlt@p@l @dZVstm@nts  sVtS {z mejkIN D@ gejm mOr\\ fr\\=gIvIN fOr\\ sIr\\iz nukVmr\\=z  kEr\\Iktr\\= dIzajnr\\= r\\ejt@ howndZu {nd k@mpowzr\\= hItowSi sAkImowtow bowT r\\Itr\\=nd fr\\Vm pr\\ivi@s Entr\\iz  @lON wID v{lkIr\\i@ kr\\An@k@lz Ii dr\\=Ektr\\= t@kESi owzAw@  @ lAr\\dZ tim Vv r\\ajtr\\=z h{nd@ld D@ skr\\Ipt  D@ gejm  Es owp@nIN Tim wAz sVN baj mej  En  81\n",
      "\n",
      "It mEt wID pAz@tIv sejlz In dZ@p{n  {nd wAz pr\\ejzd baj bowT dZ{p@niz {nd wEstr\\=n kr\\ItIks  {ftr\\= r\\ilis  It r\\@sivd dawnlowd@b@l kAntEnt  @lON wID {n Iksp{nd@d @dIS@n In nowvEmbr\\= Vv D{t jIr\\  It wAz Olsow @d{pt@d Intu m{Ng@ {nd {n r\\=IdZ@n@l vIdiow {n@mejS@n sIr\\iz  du t@ low sejlz Vv v{lkIr\\i@ kr\\An@k@lz Ii  v{lkIr\\i@ kr\\An@k@lz ajIi wAz nAt lowk@lajzd  bVt @ f{n tr\\{nzlejS@n k@mp{t@b@l wID D@ gejm  Es Iksp{nd@d @dIS@n wAz r\\ilist In   midi@  vIZ@n wUd r\\Itr\\=n t@ D@ fr\\{ntSajz wID D@ dIvEl@pm@nt Vv v{lkIr\\i@  {Zr\\= r\\Ev@luS@n fOr\\ 87\n",
      "\n",
      "D@ plejstejS@n   2\n",
      "\n",
      "gAmplej 1\n",
      "\n",
      "{z wID pr\\ivi@s v{lkiIr\\@ kr\\An@k@lz gejmz  v{lkIr\\i@ kr\\An@k@lz ajIi Iz @ t{ktIk@l r\\owl plejIN gejm wEr\\ plejr\\=z tejk k@ntr\\owl Vv @ mIl@tEr\\i jun@t {nd tejk pAr\\t In mIS@nz @gEnst En@mi fOr\\sIz  stOr\\iz Ar\\ towld Tr\\u kAmIk bUk lajk p{n@lz wID {n@mejt@d kEr\\Iktr\\= pOr\\tr\\@ts  wID k{r\\Iktr\\=z spikIN pAr\\S@li Tr\\u vojst spitS bVb@lz {nd pAr\\S@li Tr\\u @nvojst tEkst  D@ plejr\\= pr\\Agr\\Es@z Tr\\u @ sIr\\iz Vv lInir\\= mIS@nz  gr\\{dZu@li @nlAkt {z m{ps D{t k{n bi fr\\ili sk{nd Tr\\u {nd r\\iplejd {z Dej Ar\\ @nlAkt  D@ r\\ut t@ itS stOr\\i lowkejS@n An D@ m{p vEr\\iz dIpEndIN 92\n",
      "\n",
      "An {n Ind@vIdZ@w@l plejr\\=  Es @pr\\owtS  wEn wVn ApS@n Iz s@lEkt@d  D@ VDr\\= Iz sild Of t@ D@ plejr\\=  awtsajd mIS@nz  D@ plejr\\= k{r\\Iktr\\=z r\\Est In @ k{mp  wEr\\ jun@ts k{n bi kVst@majzd {nd kEr\\Iktr\\= gr\\owT @kr\\=z  @lONsajd D@ mejn stOr\\i mIS@nz Ar\\ kEr\\Iktr\\= sp@sIfIk sVb mIS@nz r\\IlejtIN t@ dIfr\\=@nt skwAd mEmbr\\=z  {ftr\\= D@ gejm  Es k@mpliS@n  @dIS@n@l Ep@sowdz Ar\\ @nlAkt  sVm Vv DEm h{vIN @ hajr\\= dIf@k@lti D{n Dowz fawnd In D@ r\\Est Vv D@ gejm  DEr\\ Ar\\ Olsow lVv sImj@lejS@n El@m@nts r\\IlejtId t@ D@ gejm 87\n",
      "\n",
      " Es tu mejn hEr\\ow@nz  OlDow Dej tejk @ vEr\\i majnr\\= r\\owl  11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/home/toure215/BERT_phonetic/DATASETS/phonetic_wikitext\")\n",
    "print(list(dataset.keys()))\n",
    "for i, ex in enumerate(dataset['train']):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(ex['text'], len(ex['text'].split()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"psktoure/BERT_WordPiece_phonetic_wikitext\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=False, truncation=False)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=15)\n",
    "\n",
    "# pd_data_frame = pd.read_csv(\n",
    "#     \"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/updated_rappers.csv\"\n",
    "# )\n",
    "# pd_data_frame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tokenized_datasets[\"train\"].to_pandas()\n",
    "#ds = ds[ds['input_ids'].apply(lambda x: len(x) > 256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1695602\n",
      "3\n",
      "16\n",
      "@\n",
      "115.20553997931118\n",
      "130.0\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))\n",
    "sentence = ds['text'].iloc[0]\n",
    "print(len(sentence.split()))  \n",
    "print(len(ds['input_ids'].iloc[0]))\n",
    "print(tokenizer.decode(6))\n",
    "ds['len'] = ds['input_ids'].map(lambda x: len(x))\n",
    "print(ds['len'].mean())\n",
    "print(ds['len'].quantile(0.5))\n",
    "print(ds['len'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[\"train\"] = Dataset.from_dict(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.filter(\n",
    "#     lambda x: \"[\" not in x[\"text\"] or \"]\" not in x[\"text\"], num_proc=15\n",
    "# ).filter(lambda x: x[\"text\"] != \"\", num_proc=15)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_ds = ds[\"train\"].to_pandas()\n",
    "# pd_ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran(\"eng-Latn\")\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def xsampa_list(word):\n",
    "    return epi.xsampa_list(word)\n",
    "\n",
    "\n",
    "def is_rhyming(word1, word2):\n",
    "    sound1 = xsampa_list(word1)\n",
    "    sound2 = xsampa_list(word2)\n",
    "    if len(sound1) < 2 or len(sound2) < 2:\n",
    "        return False\n",
    "    return sound1[-2:] == sound2[-2:]\n",
    "\n",
    "\n",
    "# Pre-compute phonetic endings for all verses\n",
    "def get_last_phonetic(word):\n",
    "    phonemes = xsampa_list(word)\n",
    "    return phonemes[-2:] if len(phonemes) >= 2 else phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_ds[\"last_word\"] = pd_ds[\"text\"].apply(lambda x: x.split()[-1])\n",
    "# pd_ds[\"phonetic_ending\"] = pd_ds[\"last_word\"].apply(get_last_phonetic)\n",
    "# pd_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert phonetic_ending lists to tuples for hashing\n",
    "# pd_ds[\"phonetic_ending\"] = pd_ds[\"phonetic_ending\"].apply(tuple)\n",
    "\n",
    "# # Group verses by their phonetic endings for quick access to rhyming pairs\n",
    "# rhyme_groups = (\n",
    "#     pd_ds.groupby(\"phonetic_ending\").apply(lambda x: x.index.tolist()).to_dict()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phonetic_endings = list(rhyme_groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the dataset\n",
    "# import random\n",
    "\n",
    "# rap_ds = pd.DataFrame(columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"])\n",
    "\n",
    "# for i in range(0, len(pd_ds), 2):\n",
    "#     last = len(rap_ds)\n",
    "#     word1 = pd_ds.iloc[i][\"last_word\"]\n",
    "#     phonetic1 = pd_ds.iloc[i][\"phonetic_ending\"]\n",
    "\n",
    "#     # Find a rhyming pair\n",
    "#     rhyming_indices = rhyme_groups.get(phonetic1, [])\n",
    "#     rhyming_idx = i  # Default to self if no other rhyme is found\n",
    "#     for idx in rhyming_indices:\n",
    "#         if idx != i:\n",
    "#             rhyming_idx = idx\n",
    "#             break\n",
    "\n",
    "#     rap_ds.loc[last] = [\n",
    "#         last,\n",
    "#         pd_ds.iloc[i][\"text\"],\n",
    "#         pd_ds.iloc[rhyming_idx][\"text\"],\n",
    "#         1,  # Label for rhyming\n",
    "#     ]\n",
    "\n",
    "#     # Find a non-rhyming pair by selecting from different phonetic endings\n",
    "#     non_rhyme_phonetic = phonetic1\n",
    "#     while non_rhyme_phonetic == phonetic1:\n",
    "#         non_rhyme_phonetic = random.choice(phonetic_endings)\n",
    "#     non_rhyme_idx = np.random.choice(rhyme_groups[non_rhyme_phonetic])\n",
    "\n",
    "#     rap_ds.loc[last + 1] = [\n",
    "#         last + 1,\n",
    "#         pd_ds.iloc[i][\"text\"],\n",
    "#         pd_ds.iloc[non_rhyme_idx][\"text\"],\n",
    "#         0,  # Label for non-rhyming\n",
    "#     ]\n",
    "\n",
    "# print(\"Final row count in rap_ds:\", len(rap_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(rap_ds, test_size=0.1, random_state=42)\n",
    "# train, val = train_test_split(train, test_size=0.1, random_state=42)\n",
    "\n",
    "# train = Dataset.from_pandas(train)\n",
    "# val = Dataset.from_pandas(val)\n",
    "# test = Dataset.from_pandas(test)\n",
    "\n",
    "# rap_ds_hf = DatasetDict({\"train\": train, \"validation\": val, \"test\": test})\n",
    "# rap_ds_hf.save_to_disk(\"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/rap_ds_hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label', '__index_level_0__'],\n",
       "        num_rows: 822322\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label', '__index_level_0__'],\n",
       "        num_rows: 91370\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label', '__index_level_0__'],\n",
       "        num_rows: 101522\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_ds_hf = load_from_disk(\"/home/toure215/BERT_phonetic/DATASETS/rap/rap_ds_hf\")\n",
    "\n",
    "rap_ds_rhyme = rap_ds_hf.filter(lambda x: x[\"label\"] == 1, num_proc=os.cpu_count() - 1)\n",
    "rap_ds_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 411009\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 45717\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 50881\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aeadfac131943d1ba0fa4778c527b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/411009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ba49e2c7874601bb2cfe20a6685e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/45717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7272c770249478eb825cbe44b65e480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50881 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rap_ds_rhyme = rap_ds_rhyme.remove_columns([\"__index_level_0__\", \"id\"])\n",
    "\n",
    "\n",
    "def add_rhyme_label(example):\n",
    "    label = example[\"sentence1\"].split()[-1]\n",
    "    return {\n",
    "        \"sentence1\": example[\"sentence1\"],\n",
    "        \"sentence2\": example[\"sentence2\"],\n",
    "        \"label\": label,\n",
    "    }\n",
    "\n",
    "\n",
    "rap_ds_rhyme = rap_ds_rhyme.map(add_rhyme_label, num_proc=os.cpu_count() - 1)\n",
    "print(rap_ds_rhyme)\n",
    "rap_ds_rhyme.save_to_disk(\"/home/toure215/BERT_phonetic/DATASETS/rap/rap_ds_rhyme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "is_phonetic = False\n",
    "model_path = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1\",\n",
    "    \"psktoure/BERT_WordPiece_wikitext-103-raw-v1\",\n",
    "]\n",
    "\n",
    "if is_phonetic:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[1])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[1])\n",
    "else:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[0])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence: str) -> str:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = \"\".join(xsampa_list(words[i]))\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def translate_function(examples):\n",
    "    examples[\"sentence1\"] = [\n",
    "        translate_sentence(sentence) for sentence in examples[\"sentence1\"]\n",
    "    ]\n",
    "    examples[\"sentence2\"] = [\n",
    "        translate_sentence(sentence) for sentence in examples[\"sentence2\"]\n",
    "    ]\n",
    "    examples[\"label\"] = [\"\".join(xsampa_list(word)) for word in examples[\"label\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "if is_phonetic:\n",
    "    rap_ds_rhyme = rap_ds_rhyme.map(\n",
    "        translate_function, num_proc=os.cpu_count() - 1, batched=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': [\"Here's a story about the three\", '(blaccblaccblaccblacc', 'My fam deep with security in the jeep', 'Try to hijack a seven-forty-seven', \"They wanna wake a sleepin' giant that ain't even asleep\"], 'sentence2': [\"You can't come hang for free\", 'See me on top but make you sick to your stomach', 'Call an ambulance when that chopper sweep', 'I can tell by her discussion', 'Call an ambulance when that chopper sweep'], 'label': ['three', '(blaccblaccblaccblacc', 'jeep', 'seven-forty-seven', 'asleep']}\n"
     ]
    }
   ],
   "source": [
    "print(rap_ds_rhyme[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase, padding=True, max_length=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token_id = tokenizer.mask_token_id\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, examples):\n",
    "\n",
    "        sentence1 = [example[\"sentence1\"] for example in examples]\n",
    "        sentence2 = [example[\"sentence2\"] for example in examples]\n",
    "        targets = [example[\"label\"] for example in examples]\n",
    "\n",
    "        encoded_targets = self.tokenizer(targets, add_special_tokens=False)\n",
    "\n",
    "        batch = self.tokenizer(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            padding=self.padding,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        for i, idx in enumerate(input_ids):\n",
    "            sep_token_indices = torch.where(idx == self.tokenizer.sep_token_id)[0]\n",
    "            start = sep_token_indices[0] - len(encoded_targets[i])\n",
    "            end = sep_token_indices[0]\n",
    "            input_ids[i, start:end] = self.mask_token_id\n",
    "            labels[i, :start] = -100\n",
    "            labels[i, end:] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": batch[\"attention_mask\"],\n",
    "            \"labels\": labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"mean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_collator = CustomDataCollator(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/fine_tuned_bert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"no\",\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rap_ds_rhyme[\"train\"],\n",
    "    eval_dataset=rap_ds_rhyme[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d90ea81023c4a318290bf7fdd71fbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/308259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2346\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/data_loader.py:559\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    561\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:184\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 184\u001b[0m         {\n\u001b[1;32m    185\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking, skip_keys\u001b[38;5;241m=\u001b[39mskip_keys)\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    187\u001b[0m         }\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:185\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    184\u001b[0m         {\n\u001b[0;32m--> 185\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    187\u001b[0m         }\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    154\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rhyme_indices(model, dataset, tokenizer, k=5):\n",
    "\n",
    "    model = model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    res = []\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        print(f\"Processing batch {i}/{len(dataset)}...\", end=\"\\r\")\n",
    "        batch = dataset[i : i + batch_size]\n",
    "        batch_sequence = [\n",
    "            {key: batch[key][j] for key in batch}\n",
    "            for j in range(len(batch[\"sentence1\"]))\n",
    "        ]\n",
    "        inputs = data_collator(batch_sequence)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            labels = inputs[\"labels\"]\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in range(len(batch[\"sentence1\"])):\n",
    "            # Identify the position of the masked token\n",
    "            masked_token_index = (\n",
    "                inputs[\"input_ids\"][j] == tokenizer.mask_token_id\n",
    "            ).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            targets = labels[j, masked_token_index]\n",
    "            top_k_indices = logits[j, masked_token_index].topk(k).indices.squeeze(0)\n",
    "            if i < 16 and j < 8:\n",
    "                print(\"targets:\", targets, \"-- top_k_indices:\", top_k_indices)\n",
    "\n",
    "            ok = True\n",
    "            for idx, target in enumerate(targets):\n",
    "                if target not in top_k_indices[idx]:\n",
    "                    ok = False\n",
    "            if ok:\n",
    "                count += 1\n",
    "\n",
    "        res.append(count / len(batch[\"sentence1\"]))\n",
    "\n",
    "    return {\"score\": np.mean(res)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([63], device='cuda:0') -- top_k_indices: tensor([  63, 7489,  451, 1465, 1315], device='cuda:0')\n",
      "targets: tensor([191], device='cuda:0') -- top_k_indices: tensor([10266,   191,  6197,  7365,  1123], device='cuda:0')\n",
      "targets: tensor([821], device='cuda:0') -- top_k_indices: tensor([ 275, 5786,  499,  821, 1343], device='cuda:0')\n",
      "targets: tensor([1738,   18], device='cuda:0') -- top_k_indices: tensor([[241,  66, 145, 233,  61],\n",
      "        [ 18,  40,  42,   6,  62]], device='cuda:0')\n",
      "targets: tensor([2886], device='cuda:0') -- top_k_indices: tensor([ 2886, 28578,   353,  6662,  8991], device='cuda:0')\n",
      "targets: tensor([181], device='cuda:0') -- top_k_indices: tensor([  181, 25987,  4511, 16038,  6242], device='cuda:0')\n",
      "targets: tensor([  28,    6, 4397,    6,   31], device='cuda:0') -- top_k_indices: tensor([[  28,   34, 1279,   56,  580],\n",
      "        [   6,   18,   42,   41,   59],\n",
      "        [4397,  808,  839,  383,  402],\n",
      "        [   6,   59,  129, 6214, 3911],\n",
      "        [  31,   81, 5908,   40,  663]], device='cuda:0')\n",
      "targets: tensor([37], device='cuda:0') -- top_k_indices: tensor([   37, 14501,    71,    15,  2557], device='cuda:0')\n",
      "Processing batch 50688/50881...\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': np.float64(0.7898269277084906)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rhyme_indices(model, rap_ds_rhyme[\"test\"], tokenizer, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': np.float64(0.7740060405655218)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'score': np.float64(0.7740060405655218)}\n",
    "{'score': np.float64(0.7898269277084906)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
