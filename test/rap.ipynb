{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import epitran\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "import kagglehub\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/toure215/.cache/kagglehub/datasets/jamiewelsh2/rap-lyrics/versions/1\n"
     ]
    }
   ],
   "source": [
    "# path = kagglehub.dataset_download(\"jamiewelsh2/rap-lyrics\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyric</th>\n",
       "      <th>next lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>rgf productions</td>\n",
       "      <td>remy boyz yahah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>remy boyz yahah</td>\n",
       "      <td>1738 ayy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>1738 ayy</td>\n",
       "      <td>im like hey whats up hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>im like hey whats up hello</td>\n",
       "      <td>seen yo pretty ass soon as you came in the door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>seen yo pretty ass soon as you came in the door</td>\n",
       "      <td>i just wanna chill got a sack for us to roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>i just wanna chill got a sack for us to roll</td>\n",
       "      <td>married to the money introduced her to my stove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>married to the money introduced her to my stove</td>\n",
       "      <td>showed her how to whip it now she remixin for low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>showed her how to whip it now she remixin for low</td>\n",
       "      <td>she my trap queen let her hit the bando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>she my trap queen let her hit the bando</td>\n",
       "      <td>we be countin up watch how far them bands go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>we be countin up watch how far them bands go</td>\n",
       "      <td>we just set a goal talkin matchin lambos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>we just set a goal talkin matchin lambos</td>\n",
       "      <td>at 56 a gram 5 a hundred grams though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>at 56 a gram 5 a hundred grams though</td>\n",
       "      <td>man i swear i love her how she work the damn pole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>man i swear i love her how she work the damn pole</td>\n",
       "      <td>hit the strip club we be lettin bands go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>hit the strip club we be lettin bands go</td>\n",
       "      <td>everybody hatin we just call them fans though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>everybody hatin we just call them fans though</td>\n",
       "      <td>in love with the money i aint never lettin go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>in love with the money i aint never lettin go</td>\n",
       "      <td>and i get high with my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>and i get high with my baby</td>\n",
       "      <td>i just left the mall im gettin fly with my bab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>i just left the mall im gettin fly with my bab...</td>\n",
       "      <td>and i can ride with my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>and i can ride with my baby</td>\n",
       "      <td>i be in the kitchen cookin pies with my baby yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Fetty Wap</td>\n",
       "      <td>Trap Queen</td>\n",
       "      <td>i be in the kitchen cookin pies with my baby yeah</td>\n",
       "      <td>and i can ride with my baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  ...                                         next lyric\n",
       "0            0  ...                                    remy boyz yahah\n",
       "1            0  ...                                           1738 ayy\n",
       "2            0  ...                        im like hey whats up hello \n",
       "3            0  ...    seen yo pretty ass soon as you came in the door\n",
       "4            0  ...       i just wanna chill got a sack for us to roll\n",
       "5            0  ...    married to the money introduced her to my stove\n",
       "6            0  ...  showed her how to whip it now she remixin for low\n",
       "7            0  ...            she my trap queen let her hit the bando\n",
       "8            0  ...       we be countin up watch how far them bands go\n",
       "9            0  ...           we just set a goal talkin matchin lambos\n",
       "10           0  ...              at 56 a gram 5 a hundred grams though\n",
       "11           0  ...  man i swear i love her how she work the damn pole\n",
       "12           0  ...           hit the strip club we be lettin bands go\n",
       "13           0  ...      everybody hatin we just call them fans though\n",
       "14           0  ...      in love with the money i aint never lettin go\n",
       "15           0  ...                       and i get high with my baby \n",
       "16           0  ...  i just left the mall im gettin fly with my bab...\n",
       "17           0  ...                       and i can ride with my baby \n",
       "18           0  ...  i be in the kitchen cookin pies with my baby yeah\n",
       "19           0  ...                       and i can ride with my baby \n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd_data_frame = pd.read_csv(\n",
    "#     \"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/updated_rappers.csv\"\n",
    "# )\n",
    "# pd_data_frame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445301\n",
      "17288\n"
     ]
    }
   ],
   "source": [
    "# print(len(pd_data_frame))\n",
    "# print(pd_data_frame[\"song\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2b40fd4c7244a6a5f36f057d775eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1181216\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds = load_dataset(\"Cropinky/rap_lyrics_english\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Lil pump', 'Lil wayne', 'Lil Durk', 'Lil B', 'Lil Uzi Vert', 'Lil Baby', 'Lil Reese', 'Lil Boosie', 'The Notorious B.I.G. ', 'Big Pun', 'Big L', 'Nas', '50 Cent', 'Prodigy', 'Action Bronson', 'Ill Bill', 'Wu-Tang Clan', 'Raekwon', 'Ghostface Killah', 'RZA', 'GZA', \"Ol' Dirty Bastard\", 'Method Man', 'Inspectah Deck', 'U-God', 'Masta Killa', 'Cappadonna', 'Kanye West', 'Lauryn Hill', 'Jean Grae', 'Lil Kim', 'Missy Elliot', 'Rah Digga', 'MC Lyte', 'Remy Ma', 'Missy Elliott', '', '', 'Foxy Brown']}\n"
     ]
    }
   ],
   "source": [
    "# print(ds[\"train\"][:39])\n",
    "# ds[\"train\"] = ds[\"train\"][40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"] = Dataset.from_dict(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9c5b354e244fb4957b677e9749d981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/1181176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0431cf591632467eae8588bf0bb9bf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/1088460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1015214\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds = ds.filter(\n",
    "#     lambda x: \"[\" not in x[\"text\"] or \"]\" not in x[\"text\"], num_proc=15\n",
    "# ).filter(lambda x: x[\"text\"] != \"\", num_proc=15)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Ooh, I like the way she move',\n",
       "  'Shorty my baby, my everything, she the truth',\n",
       "  \"Together we cool, me and her can't lose\",\n",
       "  \"Keep 'em on their feet, baby, I know they so confused\",\n",
       "  'Shorty my Beyonc√©',\n",
       "  'Durk and DeJ, Durk and DeJ, Durk and DeJ',\n",
       "  'Shorty my Beyonc√©',\n",
       "  'Durk and DeJ, Durk and DeJ, Durk and DeJ',\n",
       "  'My Beyonc√©',\n",
       "  \"Trippin' on that drank, but I know she worth it\"]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ooh, I like the way she move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shorty my baby, my everything, she the truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Together we cool, me and her can't lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keep 'em on their feet, baby, I know they so c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shorty my Beyonc√©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Durk and DeJ, Durk and DeJ, Durk and DeJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shorty my Beyonc√©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Durk and DeJ, Durk and DeJ, Durk and DeJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My Beyonc√©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trippin' on that drank, but I know she worth it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                       Ooh, I like the way she move\n",
       "1       Shorty my baby, my everything, she the truth\n",
       "2            Together we cool, me and her can't lose\n",
       "3  Keep 'em on their feet, baby, I know they so c...\n",
       "4                                  Shorty my Beyonc√©\n",
       "5           Durk and DeJ, Durk and DeJ, Durk and DeJ\n",
       "6                                  Shorty my Beyonc√©\n",
       "7           Durk and DeJ, Durk and DeJ, Durk and DeJ\n",
       "8                                         My Beyonc√©\n",
       "9    Trippin' on that drank, but I know she worth it"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd_ds = ds[\"train\"].to_pandas()\n",
    "# pd_ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epi = epitran.Epitran(\"eng-Latn\")\n",
    "\n",
    "\n",
    "# @lru_cache(maxsize=None)\n",
    "# def xsampa_list(word):\n",
    "#     return epi.xsampa_list(word)\n",
    "\n",
    "\n",
    "# def is_rhyming(word1, word2):\n",
    "#     sound1 = xsampa_list(word1)\n",
    "#     sound2 = xsampa_list(word2)\n",
    "#     if len(sound1) < 2 or len(sound2) < 2:\n",
    "#         return False\n",
    "#     return sound1[-2:] == sound2[-2:]\n",
    "\n",
    "\n",
    "# # Pre-compute phonetic endings for all verses\n",
    "# def get_last_phonetic(word):\n",
    "#     phonemes = xsampa_list(word)\n",
    "#     return phonemes[-2:] if len(phonemes) >= 2 else phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>last_word</th>\n",
       "      <th>phonetic_ending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ooh, I like the way she move</td>\n",
       "      <td>move</td>\n",
       "      <td>[u, v]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shorty my baby, my everything, she the truth</td>\n",
       "      <td>truth</td>\n",
       "      <td>[u, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Together we cool, me and her can't lose</td>\n",
       "      <td>lose</td>\n",
       "      <td>[u, z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keep 'em on their feet, baby, I know they so c...</td>\n",
       "      <td>confused</td>\n",
       "      <td>[z, d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shorty my Beyonc√©</td>\n",
       "      <td>Beyonc√©</td>\n",
       "      <td>[k, e]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text last_word phonetic_ending\n",
       "0                       Ooh, I like the way she move      move          [u, v]\n",
       "1       Shorty my baby, my everything, she the truth     truth          [u, T]\n",
       "2            Together we cool, me and her can't lose      lose          [u, z]\n",
       "3  Keep 'em on their feet, baby, I know they so c...  confused          [z, d]\n",
       "4                                  Shorty my Beyonc√©   Beyonc√©          [k, e]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd_ds[\"last_word\"] = pd_ds[\"text\"].apply(lambda x: x.split()[-1])\n",
    "# pd_ds[\"phonetic_ending\"] = pd_ds[\"last_word\"].apply(get_last_phonetic)\n",
    "# pd_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_938215/840613071.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pd_ds.groupby(\"phonetic_ending\").apply(lambda x: x.index.tolist()).to_dict()\n"
     ]
    }
   ],
   "source": [
    "# # Convert phonetic_ending lists to tuples for hashing\n",
    "# pd_ds[\"phonetic_ending\"] = pd_ds[\"phonetic_ending\"].apply(tuple)\n",
    "\n",
    "# # Group verses by their phonetic endings for quick access to rhyming pairs\n",
    "# rhyme_groups = (\n",
    "#     pd_ds.groupby(\"phonetic_ending\").apply(lambda x: x.index.tolist()).to_dict()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonetic_endings = list(rhyme_groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final row count in rap_ds: 1015214\n"
     ]
    }
   ],
   "source": [
    "# # Build the dataset\n",
    "# import random\n",
    "\n",
    "# rap_ds = pd.DataFrame(columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"])\n",
    "\n",
    "# for i in range(0, len(pd_ds), 2):\n",
    "#     last = len(rap_ds)\n",
    "#     word1 = pd_ds.iloc[i][\"last_word\"]\n",
    "#     phonetic1 = pd_ds.iloc[i][\"phonetic_ending\"]\n",
    "\n",
    "#     # Find a rhyming pair\n",
    "#     rhyming_indices = rhyme_groups.get(phonetic1, [])\n",
    "#     rhyming_idx = i  # Default to self if no other rhyme is found\n",
    "#     for idx in rhyming_indices:\n",
    "#         if idx != i:\n",
    "#             rhyming_idx = idx\n",
    "#             break\n",
    "\n",
    "#     rap_ds.loc[last] = [\n",
    "#         last,\n",
    "#         pd_ds.iloc[i][\"text\"],\n",
    "#         pd_ds.iloc[rhyming_idx][\"text\"],\n",
    "#         1,  # Label for rhyming\n",
    "#     ]\n",
    "\n",
    "#     # Find a non-rhyming pair by selecting from different phonetic endings\n",
    "#     non_rhyme_phonetic = phonetic1\n",
    "#     while non_rhyme_phonetic == phonetic1:\n",
    "#         non_rhyme_phonetic = random.choice(phonetic_endings)\n",
    "#     non_rhyme_idx = np.random.choice(rhyme_groups[non_rhyme_phonetic])\n",
    "\n",
    "#     rap_ds.loc[last + 1] = [\n",
    "#         last + 1,\n",
    "#         pd_ds.iloc[i][\"text\"],\n",
    "#         pd_ds.iloc[non_rhyme_idx][\"text\"],\n",
    "#         0,  # Label for non-rhyming\n",
    "#     ]\n",
    "\n",
    "# print(\"Final row count in rap_ds:\", len(rap_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459ee5c918eb49a4a95f0d54b03f597c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/822322 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bd31687bd949038870424352900b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/91370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bae4ea69604d9a813503bef19bd10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/101522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(rap_ds, test_size=0.1, random_state=42)\n",
    "# train, val = train_test_split(train, test_size=0.1, random_state=42)\n",
    "\n",
    "# train = Dataset.from_pandas(train)\n",
    "# val = Dataset.from_pandas(val)\n",
    "# test = Dataset.from_pandas(test)\n",
    "\n",
    "# rap_ds_hf = DatasetDict({\"train\": train, \"validation\": val, \"test\": test})\n",
    "# rap_ds_hf.save_to_disk(\"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/rap_ds_hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbfc2c0ef0a4692a6cd5da76d6521e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/822322 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9493bbd2e9b7437a87e61d23da68ecae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/91370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71409f4c3454eb292858564bbc1deb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/101522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rap_ds_hf = load_from_disk(\n",
    "    \"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/rap_ds_hf\"\n",
    ")\n",
    "\n",
    "rap_ds_rhyme = rap_ds_hf.filter(lambda x: x[\"label\"] == 1, num_proc=os.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7eb4e7504b4ce9af1c0082b9d2181e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/411009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d97d8f8119e4b9f81faa22798c4cb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/45717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1cfb59f4de4be5bf7b9ff63fc5c9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/50881 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 411009\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 45717\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 50881\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_ds_rhyme = rap_ds_rhyme.remove_columns([\"__index_level_0__\", \"id\"])\n",
    "\n",
    "\n",
    "def add_rhyme_label(example):\n",
    "    label = example[\"sentence1\"].split()[-1]\n",
    "    return {\n",
    "        \"sentence1\": example[\"sentence1\"],\n",
    "        \"sentence2\": example[\"sentence2\"],\n",
    "        \"label\": label,\n",
    "    }\n",
    "\n",
    "\n",
    "rap_ds_rhyme = rap_ds_rhyme.map(add_rhyme_label, num_proc=os.cpu_count() - 1)\n",
    "rap_ds_rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "is_phonetic = False\n",
    "\n",
    "model_path = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1\",\n",
    "    \"psktoure/BERT_WordPiece_wikitext-103-raw-v1\",\n",
    "]\n",
    "\n",
    "if is_phonetic:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[1])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[1])\n",
    "else:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[0])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence: str) -> str:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = \"\".join(xsampa_list(words[i]))\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def translate_function(examples):\n",
    "    examples[\"sentence1\"] = [\n",
    "        translate_sentence(sentence) for sentence in examples[\"sentence1\"]\n",
    "    ]\n",
    "    examples[\"sentence2\"] = [\n",
    "        translate_sentence(sentence) for sentence in examples[\"sentence2\"]\n",
    "    ]\n",
    "    examples[\"label\"] = [\"\".join(xsampa_list(word)) for word in examples[\"label\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "if is_phonetic:\n",
    "    rap_ds_rhyme = rap_ds_rhyme.map(\n",
    "        translate_function, num_proc=os.cpu_count() - 1, batched=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase, padding=True, max_length=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token_id = tokenizer.mask_token_id\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, examples):\n",
    "\n",
    "        sentence1 = [example[\"sentence1\"] for example in examples]\n",
    "        sentence2 = [example[\"sentence2\"] for example in examples]\n",
    "        targets = [example[\"label\"] for example in examples]\n",
    "\n",
    "        encoded_targets = self.tokenizer(targets, add_special_tokens=False)\n",
    "\n",
    "        batch = self.tokenizer(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            padding=self.padding,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        for i, idx in enumerate(input_ids):\n",
    "            sep_token_indices = torch.where(idx == self.tokenizer.sep_token_id)[0]\n",
    "            start = sep_token_indices[0] - len(encoded_targets[i])\n",
    "            end = sep_token_indices[0]\n",
    "            input_ids[i, start:end] = self.mask_token_id\n",
    "            labels[i, :start] = -100\n",
    "            labels[i, end:] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": batch[\"attention_mask\"],\n",
    "            \"labels\": labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"mean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_collator = CustomDataCollator(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/fine_tuned_bert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"no\",\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rap_ds_rhyme[\"train\"],\n",
    "    eval_dataset=rap_ds_rhyme[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98193653e3e641f4b7634295d3bd4f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3782c43084413a5562012c09c63d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3175690174102783, 'eval_runtime': 22.1577, 'eval_samples_per_second': 2063.258, 'eval_steps_per_second': 64.492, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a25b06db77468f97ea928800cb34dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0568487644195557, 'eval_runtime': 21.2686, 'eval_samples_per_second': 2149.505, 'eval_steps_per_second': 67.188, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e621c255ada240fd9bf80f99f9716828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9762381315231323, 'eval_runtime': 21.2673, 'eval_samples_per_second': 2149.633, 'eval_steps_per_second': 67.192, 'epoch': 3.0}\n",
      "{'train_runtime': 1753.6891, 'train_samples_per_second': 703.105, 'train_steps_per_second': 21.974, 'train_loss': 1.1264493723238613, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=38535, training_loss=1.1264493723238613, metrics={'train_runtime': 1753.6891, 'train_samples_per_second': 703.105, 'train_steps_per_second': 21.974, 'total_flos': 3.05655543996498e+16, 'train_loss': 1.1264493723238613, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rhyme_indices(model, dataset, tokenizer, k=5):\n",
    "\n",
    "    model = model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    res = []\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        print(f\"Processing batch {i}/{len(dataset)}...\", end=\"\\r\")\n",
    "        batch = dataset[i : i + batch_size]\n",
    "        batch_sequence = [\n",
    "            {key: batch[key][j] for key in batch}\n",
    "            for j in range(len(batch[\"sentence1\"]))\n",
    "        ]\n",
    "        inputs = data_collator(batch_sequence)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            labels = inputs[\"labels\"]\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in range(len(batch[\"sentence1\"])):\n",
    "            # Identify the position of the masked token\n",
    "            masked_token_index = (\n",
    "                inputs[\"input_ids\"][j] == tokenizer.mask_token_id\n",
    "            ).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            # Get the target index\n",
    "            # target_index = inputs[\"labels\"][j, masked_token_index]\n",
    "\n",
    "            targets = labels[j, masked_token_index]\n",
    "            # Get the top-k predictions\n",
    "            top_k_indices = logits[j, masked_token_index].topk(k).indices.squeeze(0)\n",
    "            if i < 16 and j < 8:\n",
    "                print(\"targets:\", targets, \"-- top_k_indices:\", top_k_indices)\n",
    "\n",
    "            # Check if the target index is in the top-k predictions\n",
    "            ok = True\n",
    "            for idx, target in enumerate(targets):\n",
    "                if target not in top_k_indices[idx]:\n",
    "                    ok = False\n",
    "            if ok:\n",
    "                count += 1\n",
    "\n",
    "        # Append accuracy for this batch\n",
    "        res.append(count / len(batch[\"sentence1\"]))\n",
    "\n",
    "    # Return the mean Top-k Accuracy\n",
    "    return {\"score\": np.mean(res)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: g batch 0/50881...tensor([2009, 1007], device='cuda:0') -- top_k_indices: tensor([[2009, 4485, 2008, 2718, 2023],\n",
      "        [1007, 1065,  999, 1012, 1033]], device='cuda:0')\n",
      "targets: tensor([2126, 1007], device='cuda:0') -- top_k_indices: tensor([[ 2126,  2360, 17812,  4931,  3100],\n",
      "        [ 1007,  1012,  1065,  1029,  1011]], device='cuda:0')\n",
      "targets: tensor([3231], device='cuda:0') -- top_k_indices: tensor([3231, 2190, 3891, 2717, 2695], device='cuda:0')\n",
      "targets: tensor([6237], device='cuda:0') -- top_k_indices: tensor([ 2606,  2073, 16200,  6771,  2045], device='cuda:0')\n",
      "targets: tensor([1026, 8945, 2015, 1028], device='cuda:0') -- top_k_indices: tensor([[ 1026,  9152,  1028,  1000,  1006],\n",
      "        [ 8945, 23033,  5811,  2015,  1012],\n",
      "        [ 2015,  4757,  3401,   999, 15094],\n",
      "        [ 1028,   999,  1000,  1065,  1007]], device='cuda:0')\n",
      "targets: tensor([2033], device='cuda:0') -- top_k_indices: tensor([ 2033, 24369, 22712,  6838,  5261], device='cuda:0')\n",
      "targets: tensor([6724], device='cuda:0') -- top_k_indices: tensor([6724, 2895, 2308, 5573, 6980], device='cuda:0')\n",
      "targets: tensor([ 1051, 11631,  1007], device='cuda:0') -- top_k_indices: tensor([[ 1051,  7910,  1041,  9779, 10381],\n",
      "        [11631,  2232,  2860,  9541, 23644],\n",
      "        [ 1007,  1024,  1012,  1065,  2509]], device='cuda:0')\n",
      "Processing batch 256/50881...\r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 8.00 GiB of which 132.56 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 5.18 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_rhyme_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrap_ds_rhyme\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mevaluate_rhyme_indices\u001b[0;34m(model, dataset, tokenizer, k)\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     21\u001b[0m     labels \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1512\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1511\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()  \u001b[38;5;66;03m# -100 index = padding token\u001b[39;00m\n\u001b[0;32m-> 1512\u001b[0m     masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1515\u001b[0m     output \u001b[38;5;241m=\u001b[39m (prediction_scores,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 8.00 GiB of which 132.56 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 5.18 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "evaluate_rhyme_indices(model, rap_ds_rhyme[\"test\"], tokenizer, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
