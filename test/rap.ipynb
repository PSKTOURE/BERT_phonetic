{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import epitran\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "import kagglehub\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'validation']\n",
      "v{lkIr\\i@ kr\\An@k@lz ajIi 3\n",
      "valkyria chronicles iii 3\n",
      "\n",
      "sEndZ now v{lkIr\\i@   Vnr\\IkOr\\dId kr\\An@k@lz dZ{p@niz    lIt  v{lkIr\\i@ Vv D@ b{t@lfild   kAm@nli r\\@fr\\=d t@ {z v{lkIr\\i@ kr\\An@k@lz ajIi awtsajd dZ@p{n  Iz @ t{ktIk@l r\\owl plejIN vIdiow gejm dIvEl@pt baj sig@ {nd midi@  vIZ@n fOr\\ D@ plejstejS@n pOr\\t@b@l  r\\ilist In dZ{njuEr\\i  In dZ@p{n  It Iz D@ Tr\\=d gejm In D@ v{lkIr\\i@ sIr\\iz  EmplojIN D@ sejm fjuZ@n Vv t{ktIk@l {nd r\\il tajm gAmplej {z Its pr\\Ed@sEsr\\=z  D@ stOr\\i r\\Vnz pEr\\@lEl t@ D@ fr\\=st gejm {nd fAlowz D@  nejml@s   @ pin@l mIl@tEr\\i jun@t sr\\=vIN D@ nejS@n Vv g{li@ dUr\\IN D@ sEk@nd jUr\\owp{n wOr\\ hu pr\\=fOr\\m sikr\\@t bl{k Apr\\=ejS@nz {nd Ar\\ pIt@d @gEnst D@ ImpIr\\i@l jun@t  k@l@m@ti r\\ejv@n   104\n",
      "senj no valkyria 3 : unrecorded chronicles  japanese : 3 , lit . valkyria of the battlefield 3  , commonly referred to as valkyria chronicles iii outside japan , is a tactical role  playing video game developed by sega and media . vision for the playstation portable . released in january 2011 in japan , it is the third game in the valkyria series . employing the same fusion of tactical and real  time gameplay as its predecessors , the story runs parallel to the first game and follows the \" nameless \" , a penal military unit serving the nation of gallia during the second europan war who perform secret black operations and are pitted against the imperial unit \" calamaty raven \" . 125\n",
      "\n",
      "D@ gejm bIg{n dIvEl@pm@nt In   k{r\\iIN owvr\\= @ lAr\\dZ pOr\\S@n Vv D@ wr\\=k dVn An v{lkIr\\i@ kr\\An@k@lz Ii  wajl It r\\Itejnd D@ st{ndr\\=d fitSr\\=z Vv D@ sIr\\iz  It Olsow Vndr\\=wEnt mVlt@p@l @dZVstm@nts  sVtS {z mejkIN D@ gejm mOr\\ fr\\=gIvIN fOr\\ sIr\\iz nukVmr\\=z  kEr\\Iktr\\= dIzajnr\\= r\\ejt@ howndZu {nd k@mpowzr\\= hItowSi sAkImowtow bowT r\\Itr\\=nd fr\\Vm pr\\ivi@s Entr\\iz  @lON wID v{lkIr\\i@ kr\\An@k@lz Ii dr\\=Ektr\\= t@kESi owzAw@  @ lAr\\dZ tim Vv r\\ajtr\\=z h{nd@ld D@ skr\\Ipt  D@ gejm  Es owp@nIN Tim wAz sVN baj mej  En  81\n",
      "the game began development in 2010 , carrying over a large portion of the work done on valkyria chronicles ii . while it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . character designer raita honjou and composer hitoshi sakimoto both returned from previous entries , along with valkyria chronicles ii director takeshi ozawa . a large team of writers handled the script . the game ' s opening theme was sung by may ' n . 93\n",
      "\n",
      "It mEt wID pAz@tIv sejlz In dZ@p{n  {nd wAz pr\\ejzd baj bowT dZ{p@niz {nd wEstr\\=n kr\\ItIks  {ftr\\= r\\ilis  It r\\@sivd dawnlowd@b@l kAntEnt  @lON wID {n Iksp{nd@d @dIS@n In nowvEmbr\\= Vv D{t jIr\\  It wAz Olsow @d{pt@d Intu m{Ng@ {nd {n r\\=IdZ@n@l vIdiow {n@mejS@n sIr\\iz  du t@ low sejlz Vv v{lkIr\\i@ kr\\An@k@lz Ii  v{lkIr\\i@ kr\\An@k@lz ajIi wAz nAt lowk@lajzd  bVt @ f{n tr\\{nzlejS@n k@mp{t@b@l wID D@ gejm  Es Iksp{nd@d @dIS@n wAz r\\ilist In   midi@  vIZ@n wUd r\\Itr\\=n t@ D@ fr\\{ntSajz wID D@ dIvEl@pm@nt Vv v{lkIr\\i@  {Zr\\= r\\Ev@luS@n fOr\\ D@ plejstejS@n   89\n",
      "it met with positive sales in japan , and was praised by both japanese and western critics . after release , it received downloadable content , along with an expanded edition in november of that year . it was also adapted into manga and an original video animation series . due to low sales of valkyria chronicles ii , valkyria chronicles iii was not localized , but a fan translation compatible with the game ' s expanded edition was released in 2014 . media . vision would return to the franchise with the development of valkyria : azure revolution for the playstation 4 . 104\n",
      "\n",
      "gAmplej 1\n",
      "gameplay 1\n",
      "\n",
      "{z wID pr\\ivi@s v{lkiIr\\@ kr\\An@k@lz gejmz  v{lkIr\\i@ kr\\An@k@lz ajIi Iz @ t{ktIk@l r\\owl plejIN gejm wEr\\ plejr\\=z tejk k@ntr\\owl Vv @ mIl@tEr\\i jun@t {nd tejk pAr\\t In mIS@nz @gEnst En@mi fOr\\sIz  stOr\\iz Ar\\ towld Tr\\u kAmIk bUk lajk p{n@lz wID {n@mejt@d kEr\\Iktr\\= pOr\\tr\\@ts  wID k{r\\Iktr\\=z spikIN pAr\\S@li Tr\\u vojst spitS bVb@lz {nd pAr\\S@li Tr\\u @nvojst tEkst  D@ plejr\\= pr\\Agr\\Es@z Tr\\u @ sIr\\iz Vv lInir\\= mIS@nz  gr\\{dZu@li @nlAkt {z m{ps D{t k{n bi fr\\ili sk{nd Tr\\u {nd r\\iplejd {z Dej Ar\\ @nlAkt  D@ r\\ut t@ itS stOr\\i lowkejS@n An D@ m{p vEr\\iz dIpEndIN An {n Ind@vIdZ@w@l plejr\\=  Es @pr\\owtS  wEn wVn ApS@n Iz s@lEkt@d  D@ VDr\\= Iz sild Of t@ D@ plejr\\=  awtsajd mIS@nz  D@ plejr\\= k{r\\Iktr\\=z r\\Est In @ k{mp  wEr\\ jun@ts k{n bi kVst@majzd {nd kEr\\Iktr\\= gr\\owT @kr\\=z  @lONsajd D@ mejn stOr\\i mIS@nz Ar\\ kEr\\Iktr\\= sp@sIfIk sVb mIS@nz r\\IlejtIN t@ dIfr\\=@nt skwAd mEmbr\\=z  {ftr\\= D@ gejm  Es k@mpliS@n  @dIS@n@l Ep@sowdz Ar\\ @nlAkt  sVm Vv DEm h{vIN @ hajr\\= dIf@k@lti D{n Dowz fawnd In D@ r\\Est Vv D@ gejm  DEr\\ Ar\\ Olsow lVv sImj@lejS@n El@m@nts r\\IlejtId t@ D@ gejm 179\n",
      "as with previous valkyira chronicles games , valkyria chronicles iii is a tactical role  playing game where players take control of a military unit and take part in missions against enemy forces . stories are told through comic book  like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . the player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . the route to each story location on the map varies depending on an individual player ' s approach : when one option is selected , the other is sealed off to the player . outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . alongside the main story missions are character  specific sub missions relating to different squad members . after the game ' s completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . there are also love simulation elements related to the game 197\n",
      "\n",
      " Es tu mejn hEr\\ow@nz  OlDow Dej tejk @ vEr\\i majnr\\= r\\owl  11\n",
      "' s two main heroines , although they take a very minor role . 14\n",
      "\n",
      "D@ gejm  Es b{t@l sIst@m  D@ blIts sIst@m  Iz k{r\\id owvr\\= dr\\=Ektli fr\\Vm v{lkiIr\\@ kr\\An@k@lz  dUr\\IN mIS@nz  plejr\\=z s@lEkt itS jun@t juzIN @ tAp dawn pr\\=spEktIv Vv D@ b{t@lfild m{p  wVns @ kEr\\Iktr\\= Iz s@lEkt@d  D@ plejr\\= muvz D@ kEr\\Iktr\\= r\\=awnd D@ b{t@lfild In Tr\\=d pr\\=s@n  @ kEr\\Iktr\\= k{n ownli {kt wVns pr\\= tr\\=n  bVt k{r\\Iktr\\=z k{n bi gr\\{nt@d mVlt@p@l tr\\=nz {t D@ IkspEns Vv VDr\\= k{r\\Iktr\\=z  tr\\=nz  itS kEr\\Iktr\\= h{z @ fild {nd dIst@ns Vv muvm@nt lIm@t@d baj DEr\\ {kS@n gejdZ  Vp t@ najn k{r\\Iktr\\=z k{n bi @sajnd t@ @ sINg@l mIS@n  dUr\\IN gAmplej  k{r\\Iktr\\=z wIl kOl awt If sVmTIN h{p@nz t@ DEm  sVtS {z DEr\\ hElT pojnts hp gEtIN low Or\\ biIN nAkt awt baj En@mi @t{ks  itS kEr\\Iktr\\= h{z sp@sIfIk  p@tEntS@lz   skIlz junik t@ itS kEr\\Iktr\\=  Dej Ar\\ dIvajd@d Intu  pr\\=s@n@l p@tEnS@l   wItS Ar\\ Inejt skIlz D{t r\\Imejn @nOltr\\=d @nlEs VDr\\=wajz dIktejt@d baj D@ stOr\\i {nd k{n iDr\\= hElp Or\\ Impid @ kEr\\Iktr\\=  {nd  b{t@l p@tEntS@lz   wItS Ar\\ gr\\own Tr\\uawt D@ gejm {nd Olwejz gr\\{nt 168\n",
      "the game ' s battle system , the blitz system , is carried over directly from valkyira chronicles . during missions , players select each unit using a top  down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third  person . a character can only act once per  turn , but characters can be granted multiple turns at the expense of other characters ' turns . each character has a field and distance of movement limited by their action gauge . up to nine characters can be assigned to a single mission . during gameplay , characters will call out if something happens to them , such as their health points  hp  getting low or being knocked out by enemy attacks . each character has specific \" potentials \" , skills unique to each character . they are divided into \" personal potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" battle potentials \" , which are grown throughout the game and always grant 195\n",
      "\n",
      "bunz t@ @ kEr\\Iktr\\=  t@ lr\\=n b{t@l p@tEntS@lz  itS kEr\\Iktr\\= h{z @ junik  m{str\\=z tejb@l   @ gr\\Id bejst skIl tejb@l D{t k{n bi juzd t@ @kwajr\\= {nd lINk dIfr\\=@nt skIlz  k{r\\Iktr\\=z Olsow h{v spES@l @bIl@tiz D{t gr\\{nt DEm tEmpr\\=Er\\i busts An D@ b{t@lfild  kr\\=t k{n {kt@vejt  dr\\=Ekt k@m{nd  {nd muv r\\=awnd D@ b{t@lfild wITawt dIplitIN hIz {kS@n pojnt gejdZ  D@ kEr\\Iktr\\= r\\il@ k{n SIft Intu hr\\=  v{lkIr\\i@ fOr\\m  {nd bIkVm InvIns@b@l  wajl Imk@ k{n tAr\\g@t mVlt@p@l En@mi jun@ts wID hr\\= hEvi wEp@n  82\n",
      "boons to a character . to learn battle potentials , each character has a unique \" masters table \" , a grid  based skill table that can be used to acquire and link different skills . characters also have special abilities that grant them temporary boosts on the battlefield : kurt can activate \" direct command \" and move around the battlefield without depleting his action point gauge , the character reila can shift into her \" valkyria form \" and become invincible , while imca can target multiple enemy units with her heavy weapon . 96\n",
      "\n",
      "tr\\ups Ar\\ dIvajd@d Intu fajv kl{s@z  skawts  SAktr\\upr\\=z  EndZ@nIr\\z  l{nsr\\=z {nd Ar\\mr\\=d sowldZr\\=  tr\\upr\\=z k{n swItS kl{s@z baj tSejndZIN DEr\\ @sajnd wEp@n  tSejndZIN kl{s dowz nAt gr\\ejtli @fEkt D@ st{ts gejnd wajl In @ pr\\ivi@s kl{s  wID vIktr\\=i In b{t@l  IkspIr\\i@ns pojnts Ar\\ @wOr\\d@d t@ D@ skwAd  wItS Ar\\ dIstr\\Ibj@t@d Intu fajv dIfr\\=@nt {tr\\@bjuts SEr\\d baj D@ Intajr\\= skwAd  @ fitSr\\= dIfr\\=IN fr\\Vm r\\=li gejmz  mET@d Vv dIstr\\IbjutIN t@ dIfr\\=@nt jun@t tajps  72\n",
      "troops are divided into five classes : scouts , shocktroopers , engineers , lancers and armored soldier . troopers can switch classes by changing their assigned weapon . changing class does not greatly affect the stats gained while in a previous class . with victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . 84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk(\"/home/toure215/BERT_phonetic/DATASETS/phonetic_wikitext-103-raw-v1\")\n",
    "print(list(dataset.keys()))\n",
    "for i, ex in enumerate(dataset['train']):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(ex['text'], len(ex['text'].split()))\n",
    "    print(ex['original_text'], len(ex['original_text'].split()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'original_text'],\n",
       "        num_rows: 1210449\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'original_text'],\n",
       "        num_rows: 2610\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = concatenate_datasets([dataset['train'], dataset['test']])\n",
    "dataset[\"train\"] = dataset_train\n",
    "del dataset[\"test\"]\n",
    "\n",
    "dataset\n",
    "\n",
    "# pd_data_frame = pd.read_csv(\n",
    "#     \"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/updated_rappers.csv\"\n",
    "# )\n",
    "# pd_data_frame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8285b605e0ea4d49a0e429e29b94a11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/1210449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc71d2c07b34fd1b17b5595eae7fd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"/home/toure215/BERT_phonetic/DATASETS/phonetic_wikitext\")\n",
    "# print(len(pd_data_frame))\n",
    "# print(pd_data_frame[\"song\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"Cropinky/rap_lyrics_english\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ds[\"train\"][:39])\n",
    "# ds[\"train\"] = ds[\"train\"][40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[\"train\"] = Dataset.from_dict(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.filter(\n",
    "#     lambda x: \"[\" not in x[\"text\"] or \"]\" not in x[\"text\"], num_proc=15\n",
    "# ).filter(lambda x: x[\"text\"] != \"\", num_proc=15)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_ds = ds[\"train\"].to_pandas()\n",
    "# pd_ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran(\"eng-Latn\")\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def xsampa_list(word):\n",
    "    return epi.xsampa_list(word)\n",
    "\n",
    "\n",
    "def is_rhyming(word1, word2):\n",
    "    sound1 = xsampa_list(word1)\n",
    "    sound2 = xsampa_list(word2)\n",
    "    if len(sound1) < 2 or len(sound2) < 2:\n",
    "        return False\n",
    "    return sound1[-2:] == sound2[-2:]\n",
    "\n",
    "\n",
    "# Pre-compute phonetic endings for all verses\n",
    "def get_last_phonetic(word):\n",
    "    phonemes = xsampa_list(word)\n",
    "    return phonemes[-2:] if len(phonemes) >= 2 else phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_ds[\"last_word\"] = pd_ds[\"text\"].apply(lambda x: x.split()[-1])\n",
    "# pd_ds[\"phonetic_ending\"] = pd_ds[\"last_word\"].apply(get_last_phonetic)\n",
    "# pd_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert phonetic_ending lists to tuples for hashing\n",
    "# pd_ds[\"phonetic_ending\"] = pd_ds[\"phonetic_ending\"].apply(tuple)\n",
    "\n",
    "# # Group verses by their phonetic endings for quick access to rhyming pairs\n",
    "# rhyme_groups = (\n",
    "#     pd_ds.groupby(\"phonetic_ending\").apply(lambda x: x.index.tolist()).to_dict()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phonetic_endings = list(rhyme_groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the dataset\n",
    "# import random\n",
    "\n",
    "# rap_ds = pd.DataFrame(columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"])\n",
    "\n",
    "# for i in range(0, len(pd_ds), 2):\n",
    "#     last = len(rap_ds)\n",
    "#     word1 = pd_ds.iloc[i][\"last_word\"]\n",
    "#     phonetic1 = pd_ds.iloc[i][\"phonetic_ending\"]\n",
    "\n",
    "#     # Find a rhyming pair\n",
    "#     rhyming_indices = rhyme_groups.get(phonetic1, [])\n",
    "#     rhyming_idx = i  # Default to self if no other rhyme is found\n",
    "#     for idx in rhyming_indices:\n",
    "#         if idx != i:\n",
    "#             rhyming_idx = idx\n",
    "#             break\n",
    "\n",
    "#     rap_ds.loc[last] = [\n",
    "#         last,\n",
    "#         pd_ds.iloc[i][\"text\"],\n",
    "#         pd_ds.iloc[rhyming_idx][\"text\"],\n",
    "#         1,  # Label for rhyming\n",
    "#     ]\n",
    "\n",
    "#     # Find a non-rhyming pair by selecting from different phonetic endings\n",
    "#     non_rhyme_phonetic = phonetic1\n",
    "#     while non_rhyme_phonetic == phonetic1:\n",
    "#         non_rhyme_phonetic = random.choice(phonetic_endings)\n",
    "#     non_rhyme_idx = np.random.choice(rhyme_groups[non_rhyme_phonetic])\n",
    "\n",
    "#     rap_ds.loc[last + 1] = [\n",
    "#         last + 1,\n",
    "#         pd_ds.iloc[i][\"text\"],\n",
    "#         pd_ds.iloc[non_rhyme_idx][\"text\"],\n",
    "#         0,  # Label for non-rhyming\n",
    "#     ]\n",
    "\n",
    "# print(\"Final row count in rap_ds:\", len(rap_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(rap_ds, test_size=0.1, random_state=42)\n",
    "# train, val = train_test_split(train, test_size=0.1, random_state=42)\n",
    "\n",
    "# train = Dataset.from_pandas(train)\n",
    "# val = Dataset.from_pandas(val)\n",
    "# test = Dataset.from_pandas(test)\n",
    "\n",
    "# rap_ds_hf = DatasetDict({\"train\": train, \"validation\": val, \"test\": test})\n",
    "# rap_ds_hf.save_to_disk(\"/home/toure215/Documents/BERT_phonetic/DATASETS/rap/rap_ds_hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label', '__index_level_0__'],\n",
       "        num_rows: 822322\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label', '__index_level_0__'],\n",
       "        num_rows: 91370\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label', '__index_level_0__'],\n",
       "        num_rows: 101522\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_ds_hf = load_from_disk(\"/home/toure215/BERT_phonetic/DATASETS/rap/rap_ds_hf\")\n",
    "\n",
    "rap_ds_rhyme = rap_ds_hf.filter(lambda x: x[\"label\"] == 1, num_proc=os.cpu_count() - 1)\n",
    "rap_ds_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 411009\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 45717\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 50881\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aeadfac131943d1ba0fa4778c527b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/411009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ba49e2c7874601bb2cfe20a6685e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/45717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7272c770249478eb825cbe44b65e480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50881 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rap_ds_rhyme = rap_ds_rhyme.remove_columns([\"__index_level_0__\", \"id\"])\n",
    "\n",
    "\n",
    "def add_rhyme_label(example):\n",
    "    label = example[\"sentence1\"].split()[-1]\n",
    "    return {\n",
    "        \"sentence1\": example[\"sentence1\"],\n",
    "        \"sentence2\": example[\"sentence2\"],\n",
    "        \"label\": label,\n",
    "    }\n",
    "\n",
    "\n",
    "rap_ds_rhyme = rap_ds_rhyme.map(add_rhyme_label, num_proc=os.cpu_count() - 1)\n",
    "print(rap_ds_rhyme)\n",
    "rap_ds_rhyme.save_to_disk(\"/home/toure215/BERT_phonetic/DATASETS/rap/rap_ds_rhyme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "is_phonetic = False\n",
    "model_path = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1\",\n",
    "    \"psktoure/BERT_WordPiece_wikitext-103-raw-v1\",\n",
    "]\n",
    "\n",
    "if is_phonetic:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[1])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[1])\n",
    "else:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[0])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence: str) -> str:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = \"\".join(xsampa_list(words[i]))\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def translate_function(examples):\n",
    "    examples[\"sentence1\"] = [\n",
    "        translate_sentence(sentence) for sentence in examples[\"sentence1\"]\n",
    "    ]\n",
    "    examples[\"sentence2\"] = [\n",
    "        translate_sentence(sentence) for sentence in examples[\"sentence2\"]\n",
    "    ]\n",
    "    examples[\"label\"] = [\"\".join(xsampa_list(word)) for word in examples[\"label\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "if is_phonetic:\n",
    "    rap_ds_rhyme = rap_ds_rhyme.map(\n",
    "        translate_function, num_proc=os.cpu_count() - 1, batched=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': [\"Here's a story about the three\", '(blaccblaccblaccblacc', 'My fam deep with security in the jeep', 'Try to hijack a seven-forty-seven', \"They wanna wake a sleepin' giant that ain't even asleep\"], 'sentence2': [\"You can't come hang for free\", 'See me on top but make you sick to your stomach', 'Call an ambulance when that chopper sweep', 'I can tell by her discussion', 'Call an ambulance when that chopper sweep'], 'label': ['three', '(blaccblaccblaccblacc', 'jeep', 'seven-forty-seven', 'asleep']}\n"
     ]
    }
   ],
   "source": [
    "print(rap_ds_rhyme[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase, padding=True, max_length=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token_id = tokenizer.mask_token_id\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, examples):\n",
    "\n",
    "        sentence1 = [example[\"sentence1\"] for example in examples]\n",
    "        sentence2 = [example[\"sentence2\"] for example in examples]\n",
    "        targets = [example[\"label\"] for example in examples]\n",
    "\n",
    "        encoded_targets = self.tokenizer(targets, add_special_tokens=False)\n",
    "\n",
    "        batch = self.tokenizer(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            padding=self.padding,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        for i, idx in enumerate(input_ids):\n",
    "            sep_token_indices = torch.where(idx == self.tokenizer.sep_token_id)[0]\n",
    "            start = sep_token_indices[0] - len(encoded_targets[i])\n",
    "            end = sep_token_indices[0]\n",
    "            input_ids[i, start:end] = self.mask_token_id\n",
    "            labels[i, :start] = -100\n",
    "            labels[i, end:] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": batch[\"attention_mask\"],\n",
    "            \"labels\": labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"mean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_collator = CustomDataCollator(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/fine_tuned_bert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"no\",\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rap_ds_rhyme[\"train\"],\n",
    "    eval_dataset=rap_ds_rhyme[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d90ea81023c4a318290bf7fdd71fbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/308259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2346\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/data_loader.py:559\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    561\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:184\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 184\u001b[0m         {\n\u001b[1;32m    185\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking, skip_keys\u001b[38;5;241m=\u001b[39mskip_keys)\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    187\u001b[0m         }\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:185\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    184\u001b[0m         {\n\u001b[0;32m--> 185\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    187\u001b[0m         }\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/utils/operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    154\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rhyme_indices(model, dataset, tokenizer, k=5):\n",
    "\n",
    "    model = model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    res = []\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        print(f\"Processing batch {i}/{len(dataset)}...\", end=\"\\r\")\n",
    "        batch = dataset[i : i + batch_size]\n",
    "        batch_sequence = [\n",
    "            {key: batch[key][j] for key in batch}\n",
    "            for j in range(len(batch[\"sentence1\"]))\n",
    "        ]\n",
    "        inputs = data_collator(batch_sequence)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            labels = inputs[\"labels\"]\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in range(len(batch[\"sentence1\"])):\n",
    "            # Identify the position of the masked token\n",
    "            masked_token_index = (\n",
    "                inputs[\"input_ids\"][j] == tokenizer.mask_token_id\n",
    "            ).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            targets = labels[j, masked_token_index]\n",
    "            top_k_indices = logits[j, masked_token_index].topk(k).indices.squeeze(0)\n",
    "            if i < 16 and j < 8:\n",
    "                print(\"targets:\", targets, \"-- top_k_indices:\", top_k_indices)\n",
    "\n",
    "            ok = True\n",
    "            for idx, target in enumerate(targets):\n",
    "                if target not in top_k_indices[idx]:\n",
    "                    ok = False\n",
    "            if ok:\n",
    "                count += 1\n",
    "\n",
    "        res.append(count / len(batch[\"sentence1\"]))\n",
    "\n",
    "    return {\"score\": np.mean(res)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([63], device='cuda:0') -- top_k_indices: tensor([  63, 7489,  451, 1465, 1315], device='cuda:0')\n",
      "targets: tensor([191], device='cuda:0') -- top_k_indices: tensor([10266,   191,  6197,  7365,  1123], device='cuda:0')\n",
      "targets: tensor([821], device='cuda:0') -- top_k_indices: tensor([ 275, 5786,  499,  821, 1343], device='cuda:0')\n",
      "targets: tensor([1738,   18], device='cuda:0') -- top_k_indices: tensor([[241,  66, 145, 233,  61],\n",
      "        [ 18,  40,  42,   6,  62]], device='cuda:0')\n",
      "targets: tensor([2886], device='cuda:0') -- top_k_indices: tensor([ 2886, 28578,   353,  6662,  8991], device='cuda:0')\n",
      "targets: tensor([181], device='cuda:0') -- top_k_indices: tensor([  181, 25987,  4511, 16038,  6242], device='cuda:0')\n",
      "targets: tensor([  28,    6, 4397,    6,   31], device='cuda:0') -- top_k_indices: tensor([[  28,   34, 1279,   56,  580],\n",
      "        [   6,   18,   42,   41,   59],\n",
      "        [4397,  808,  839,  383,  402],\n",
      "        [   6,   59,  129, 6214, 3911],\n",
      "        [  31,   81, 5908,   40,  663]], device='cuda:0')\n",
      "targets: tensor([37], device='cuda:0') -- top_k_indices: tensor([   37, 14501,    71,    15,  2557], device='cuda:0')\n",
      "Processing batch 50688/50881...\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': np.float64(0.7898269277084906)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rhyme_indices(model, rap_ds_rhyme[\"test\"], tokenizer, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': np.float64(0.7740060405655218)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'score': np.float64(0.7740060405655218)}\n",
    "{'score': np.float64(0.7898269277084906)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
