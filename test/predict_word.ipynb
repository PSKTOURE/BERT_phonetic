{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import epitran\n",
    "from functools import lru_cache\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_phonetic = True\n",
    "epi = epitran.Epitran(\"eng-Latn\")\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def xsampa_list(word: str) -> list:\n",
    "    return epi.xsampa_list(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ah why this boding start this sudden pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that wings my pulse and shoots from vein to vein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what mean regardless of yon midnight bell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these earthborn visions saddening oer my cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what strange disorder prompts these thoughts t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Verse\n",
       "0          ah why this boding start this sudden pain\n",
       "1   that wings my pulse and shoots from vein to vein\n",
       "2          what mean regardless of yon midnight bell\n",
       "3      these earthborn visions saddening oer my cell\n",
       "4  what strange disorder prompts these thoughts t..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset = pd.read_csv('/home/toure215/BERT_phonetic/DATASETS/verses/super_verses.csv')\n",
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ah why this boding start this sudden pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that wings my pulse and shoots from vein to vein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what mean regardless of yon midnight bell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these earthborn visions saddening oer my cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what strange disorder prompts these thoughts t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text\n",
       "0          ah why this boding start this sudden pain\n",
       "1   that wings my pulse and shoots from vein to vein\n",
       "2          what mean regardless of yon midnight bell\n",
       "3      these earthborn visions saddening oer my cell\n",
       "4  what strange disorder prompts these thoughts t..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset = pd_dataset.rename({\"Verse\": \"input_text\"}, axis='columns')\n",
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_word(verse: str) -> str:\n",
    "    return verse.split()[-1]\n",
    "\n",
    "def mask_last_word(verse: str) -> str:\n",
    "    words = verse.split()\n",
    "    words[-1] = '[MASK]'\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset['target_word'] = pd_dataset['input_text'].apply(get_last_word)\n",
    "# pd_dataset['input_text'] = pd_dataset['input_text'].apply(mask_last_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ah why this boding start this sudden pain</td>\n",
       "      <td>pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that wings my pulse and shoots from vein to vein</td>\n",
       "      <td>vein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what mean regardless of yon midnight bell</td>\n",
       "      <td>bell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these earthborn visions saddening oer my cell</td>\n",
       "      <td>cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what strange disorder prompts these thoughts t...</td>\n",
       "      <td>glow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text target_word\n",
       "0          ah why this boding start this sudden pain        pain\n",
       "1   that wings my pulse and shoots from vein to vein        vein\n",
       "2          what mean regardless of yon midnight bell        bell\n",
       "3      these earthborn visions saddening oer my cell        cell\n",
       "4  what strange disorder prompts these thoughts t...        glow"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(pd_dataset, test_size=0.1, random_state=42, shuffle=True)\n",
    "train, val = train_test_split(train, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = Dataset.from_pandas(train)\n",
    "hf_val = Dataset.from_pandas(val)\n",
    "hf_test = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_text', 'target_word'],\n",
       "        num_rows: 440950\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_text', 'target_word'],\n",
       "        num_rows: 48995\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_text', 'target_word'],\n",
       "        num_rows: 54439\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset = DatasetDict({\"train\": hf_train, \"validation\": hf_val, \"test\": hf_test}).remove_columns(['__index_level_0__'])\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "model_path = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"psktoure/BERT_BPE_phonetic_wikitext-103-raw-v1\",\n",
    "    \"psktoure/BERT_WordLevel_phonetic_wikitext-103-raw-v1\",\n",
    "]\n",
    "\n",
    "if is_phonetic:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[-1])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[-1])\n",
    "else:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_path[0])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence: str) -> str:\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = ' '.join(xsampa_list(words[i]))\n",
    "    return ' '.join(words)\n",
    "\n",
    "def translate_function(examples):\n",
    "    examples['input_text'] = [translate_sentence(sentence) for sentence in examples['input_text']]\n",
    "    examples['target_word'] = [' '.join(xsampa_list(word)) for word in examples['target_word']]\n",
    "    return examples\n",
    "    \n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['input_text'], padding='max_length', truncation=True, max_length=50)\n",
    "    targets = tokenizer(examples['target_word'], padding='max_length', truncation=True, max_length=5)\n",
    "    inputs['labels'] = targets['input_ids']\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ac1ce611374f739d0d7b5da61810f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/440950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc4b6fc09234382ae4564b95244a76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/48995 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c877f462df414788bc078a93b204a4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/54439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if is_phonetic:\n",
    "    hf_dataset = hf_dataset.map(translate_function, batched=True, num_proc=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = hf_dataset.map(tokenize_function, batched=True, num_proc=15, remove_columns=['input_text', 'target_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   \n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "class CustomDataCollator:\n",
    "    def __init__(\n",
    "        self, tokenizer: PreTrainedTokenizerBase, padding=True, max_length=128\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token_id = tokenizer.mask_token_id\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, examples):\n",
    "\n",
    "        input_text = [example[\"input_text\"] for example in examples]\n",
    "        targets = [example[\"target_word\"] for example in examples]\n",
    "\n",
    "        encoded_targets = self.tokenizer(\n",
    "            targets,\n",
    "            add_special_tokens=False,\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        batch = self.tokenizer(\n",
    "            input_text,\n",
    "            padding=self.padding,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        for i, idx in enumerate(input_ids):\n",
    "            sep_token_indices = torch.where(idx == self.tokenizer.sep_token_id)[0]\n",
    "            start = sep_token_indices[0] - len(encoded_targets[i])\n",
    "            end = sep_token_indices[0]\n",
    "            input_ids[i, start:end] = self.mask_token_id\n",
    "            labels[i, :start] = -100\n",
    "            labels[i, end:] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": batch[\"attention_mask\"],\n",
    "            \"labels\": labels,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "data_collator = CustomDataCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_token_id:  4 \n",
      "mask_token: [MASK]\n",
      "[{'input_text': 'w a j d w e j v D @ f l e j m I N s O r\\\\ d { n d s E n d o w s E n d', 'target_word': 's E n d'}, {'input_text': 'D @ m A r\\\\ b @ l l i p s O r\\\\ S r\\\\ I N k s O r\\\\ b r\\\\= n z', 'target_word': 'b r\\\\= n z'}]\n",
      "input_ids : tensor([[ 1, 16, 30, 14, 12, 16, 31, 14, 26, 23,  5, 29, 13, 31, 14, 19,  9, 36,\n",
      "         10, 32,  6, 11, 12, 17,  7, 12, 10, 20,  7, 12, 33, 16,  4,  4,  4,  4,\n",
      "          2],\n",
      "        [ 1, 23,  5, 19, 25,  6, 11, 28,  5, 13, 13, 18, 24, 10, 32,  6, 11, 37,\n",
      "          6, 11,  9, 36, 15, 10, 32,  6, 11,  4,  4,  4,  4,  4,  2,  3,  3,  3,\n",
      "          3]])\n",
      "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])\n",
      "labels : tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100,   10,   20,    7,   12,\n",
      "         -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100,   28,    6,   22,    7,   21, -100, -100, -100, -100,\n",
      "         -100]])\n",
      "[UNK]\n"
     ]
    }
   ],
   "source": [
    "sample = hf_dataset['train'][:2]\n",
    "sample_list = [{key: sample[key][i] for key in sample} for i in range(len(sample['input_text']))]\n",
    "print(\"mask_token_id: \", tokenizer.mask_token_id, \"\\nmask_token:\", tokenizer.mask_token)\n",
    "print(sample_list)\n",
    "c = data_collator(sample_list)\n",
    "for key in c:\n",
    "    print(key ,\":\", c[key])\n",
    "print(tokenizer.decode(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme_score(word1: str, word2: str) -> int:\n",
    "    if not is_phonetic:    \n",
    "        end1 = xsampa_list(word1)\n",
    "        end2 = xsampa_list(word2)\n",
    "    else:\n",
    "        end1 = word1\n",
    "        end2 = word2\n",
    "    length = min(len(end1), len(end2), 3)\n",
    "    end1 = end1[-length:]\n",
    "    end2 = end2[-length:]\n",
    "    return SequenceMatcher(None, end1, end2).ratio()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = torch.argmax(pred.predictions, dim=-1)\n",
    "    batch_size = 32  \n",
    "    total_rhyme_score = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(0, len(preds), batch_size):\n",
    "        batch_preds = preds[i:i + batch_size]\n",
    "        batch_labels = pred.label_ids[i:i + batch_size]\n",
    "\n",
    "        # Decode predictions and labels in batches\n",
    "        decoded_preds = tokenizer.batch_decode(batch_preds, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(batch_labels, skip_special_tokens=True)\n",
    "\n",
    "        # Compute rhyme scores for the batch\n",
    "        batch_rhyme_scores = [\n",
    "            rhyme_score(pred_word, target_word)\n",
    "            for pred_word, target_word in zip(decoded_preds, decoded_labels)\n",
    "        ]\n",
    "        \n",
    "        total_rhyme_score += sum(batch_rhyme_scores)\n",
    "        count += len(batch_rhyme_scores)\n",
    "\n",
    "    # Compute the mean rhyme score\n",
    "    mean_rhyme_score = total_rhyme_score / count if count > 0 else 0\n",
    "    return {\"rhyme_score\": mean_rhyme_score}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toure215/miniconda3/envs/bert/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/tmp/verses',\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    eval_strategy='epoch',\n",
    "    logging_strategy='no',\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=hf_dataset['train'],\n",
    "    eval_dataset=hf_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5877a01cff564afe97a9205bc32f1972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e677b0b92f844adae865b939a185dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8288426399230957, 'eval_runtime': 10.4753, 'eval_samples_per_second': 4677.186, 'eval_steps_per_second': 18.329, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7ce5358e38423ea734e4aab48e0b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7825145721435547, 'eval_runtime': 10.7593, 'eval_samples_per_second': 4553.723, 'eval_steps_per_second': 17.845, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce6027a6e0f43efbbb35fb2397d6569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.764601230621338, 'eval_runtime': 10.6198, 'eval_samples_per_second': 4613.566, 'eval_steps_per_second': 18.079, 'epoch': 3.0}\n",
      "{'train_runtime': 698.4524, 'train_samples_per_second': 1893.973, 'train_steps_per_second': 7.401, 'train_loss': 2.813008024097988, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5169, training_loss=2.813008024097988, metrics={'train_runtime': 698.4524, 'train_samples_per_second': 1893.973, 'train_steps_per_second': 7.401, 'total_flos': 4.457153434383468e+16, 'train_loss': 2.813008024097988, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rhyme(model, dataset, tokenizer):\n",
    "    model = model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    rhyme_scores = []\n",
    "    batch_size = 256\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        # if i > 16:\n",
    "        #     break\n",
    "        print(f\"Processing example {i}/{len(dataset)} ...\", end=\"\\r\")\n",
    "        batch = dataset[i : i + batch_size]\n",
    "        batch_sequence = [{key: batch[key][j] for key in batch} for j in range(len(batch[\"input_text\"]))]\n",
    "        inputs = data_collator(batch_sequence)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        for j in range(len(batch[\"input_text\"])):\n",
    "            masked_token_index = torch.where(inputs[\"input_ids\"][j] == tokenizer.mask_token_id)[0]\n",
    "            predicted_index = logits[j, masked_token_index].argmax(-1)\n",
    "            predicted_word = tokenizer.decode(predicted_index)\n",
    "            target = tokenizer.decode(inputs[\"labels\"][j, masked_token_index])\n",
    "            if i < 16 and j < 8:\n",
    "                print('predicted_word:', predicted_word, '-- target_word:', target)\n",
    "            rhyme_scores.append(rhyme_score(predicted_word, target))\n",
    "\n",
    "    return {\"score\": np.mean(rhyme_scores)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[MASK]\n",
      "{'input_text': 'I z h i h u z v I z @ dZ I n D @ l e j z i m I s t', 'target_word': 'm I s t'}\n",
      "{'input_ids': [1, 9, 21, 35, 18, 35, 34, 21, 26, 9, 21, 5, 39, 9, 7, 23, 5, 13, 31, 14, 21, 18, 19, 9, 10, 8, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "b_\n",
      "s_\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.mask_token_id)\n",
    "print(tokenizer.mask_token)\n",
    "print(hf_dataset['test'][0])\n",
    "print(tokenizer(hf_dataset['test'][0]['input_text']))\n",
    "print(tokenizer.decode(103))\n",
    "print(tokenizer.decode(102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_word: s e j d -- target_word: m I s t\n",
      "predicted_word: d I s a j n d -- target_word: w I T s t U d\n",
      "predicted_word: b O n -- target_word: w O l\n",
      "predicted_word: h r r \\ z -- target_word: h { n d z\n",
      "predicted_word: I r \\ r r r r @ r e j S @ n -- target_word: h I r \\ @ f r \\= d S a j r \\\n",
      "predicted_word: s e j z -- target_word: v e j s\n",
      "predicted_word: f r r r z -- target_word: o w v r \\=\n",
      "predicted_word: s e j d -- target_word: w a j f\n",
      "Processing example 54272/54439 ...\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': np.float64(0.48488522321619915)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rhyme(model, hf_dataset['test'], tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import ctypes\n",
    "# import torch\n",
    "# gc.collect()\n",
    "# libc = ctypes.CDLL(\"libc.so.6\") # clearing cache\n",
    "# libc.malloc_trim(0)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
