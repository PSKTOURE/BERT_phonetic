# Training model args:
tm::dataset_path==DATASETS/phonetic_wikitext
tm::tokenizer_path==tokenizers/tokenizer_phonetic_WordPiece
tm::tokenizer_type==WordPiece
tm::is_phonetic==TRUE
tm::num_epochs==40
tm::max_steps==400000
tm::fp16==TRUE
tm::batch_size==256
tm::d_lambda==0.5
tm::lr==0.0001
tm::max_length==128
tm::log_dir==logs
tm::model_dir==models
tm::percent==0.2

# Fine_tuning args:
ft::model_path==psktoure/BERT_WordLevel_phonetic_bookcorpus_0.1
ft::is_phonetic==TRUE
ft::phoneme==FALSE
ft::num_iterations==3
ft::all==TRUE

# Training tokenizer args:
tt::dataset_path==DATASETS/phonetic_wikitext
tt::tokenizer_type==BPE
tt::is_phonetic==TRUE