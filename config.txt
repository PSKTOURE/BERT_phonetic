# Training model args:
tm::dataset_path==DATASETS/phonetic_wikitext
tm::tokenizer_path==tokenizers/tokenizer_phonetic_WordPiece
tm::tokenizer_type==WordPiece
tm::is_phonetic==TRUE
tm::num_epochs==40
tm::max_steps==-1
tm::fp16==TRUE
tm::batch_size==128
tm::distillation_lambda==0.1
tm::lr==0.0001
tm::max_length==256
tm::log_dir==logs
tm::model_dir==models
tm::percent==0.2

# Fine_tuning args:
ft::model_path==psktoure/BERT_WordLevel_phonetic_bookcorpus_0.1
ft::tokenizer_path==psktoure/BERT_WordLevel_phonetic_bookcorpus_0.1
ft::is_phonetic==TRUE
ft::phoneme==FALSE
ft::num_iterations==3
ft::all==TRUE

# Training tokenizer args:
tt::dataset_path==DATASETS/phonetic_wikitext
tt::tokenizer_type==WordPiece
tt::is_phonetic==TRUE