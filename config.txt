# Training model args:
tm::dataset_path==DATASETS/phonetic_bookcorpus
tm::tokenizer_path==tokenizers/tokenizer_phonetic_BPE
tm::tokenizer_type==BPE
tm::is_phonetic==TRUE
tm::num_epochs==40
tm::max_steps==-1
tm::fp16==TRUE
tm::batch_size==320
tm::lr==0.0001
tm::max_length==128
tm::log_dir==logs
tm::model_dir==models
tm::percent==0.2

# Fine_tuning args:
ft::model_path==psktoure/BERT_WordLevel_phonetic_bookcorpus_0.1
ft::tokenizer_path==psktoure/BERT_WordLevel_phonetic_bookcorpus_0.1
ft::is_phonetic==TRUE
ft::phoneme==FALSE
ft::num_iterations==3
ft::all==TRUE

# Training tokenizer args:
tt::dataset_path==DATASETS/phonetic_bookcorpus
tt::tokenizer_type==BPE
tt::is_phonetic==TRUE